# HTTP 前世今生

## TCP 和 UDP

### TCP 

#### 报文格式

<img src="net/http/resources/tcp_1.png" style="width:50%">

- 源端口号（16位）：发送方端口
- 目标端口号（16位）：接收方端口
- 序列号（32位）：本报文段数据的第一个字节的序号
- 确认号（32位）：期望收到对方下一个数据字节的序号（用于确认应答）
- 数据偏移（4位）：TCP头部长度（单位4字节），用于指示数据部分起始位置
- 保留（6位）：保留位，未使用
- 控制位（6位）：URG、ACK、PSH、RST、SYN、FIN，分别表示不同的控制功能（如握手、断开等）
- 窗口大小（16位）：接收窗口大小，用于流量控制
- 校验和（16位）：对整个TCP报文段进行校验，保证数据完整性
- 紧急指针（16位）：紧急数据的结束位置（配合URG使用）
- 选项（可选）：如最大报文段长度MSS、窗口扩大因子等
- 数据：实际要传输的数据内容

#### 如何确保可靠性

1. 三次握手，四次挥手确保链接和断开的稳定可靠。

**三次握手**

- client 发送一个带 SYN 的数据包，随机生成初始化序列号 seq=x,随后进入 SYNC_SEND 状态。
- 服务端收到后，发送一个同时带 SYN 和 ACK 标志的包且携带一个随机序列号 seq = y，此时 ACK = x+1。 随后进入 SYNC_RECV 状态。
- 客户端收到后，发送一个 ACK 包，此时 ACK = y +1, 随后进入 ESTABLISHED，服务端收到后，也进入 ESTABLISHED，连接建立完成。


**四次挥手**

- 客户端发送 FIN 标志的数据包，代表我没数据发送了，但是还可以接收数据，随后进入 FIN_WAIT_1 状态。
- 服务端收到 FIN 后，发送 ACK 包，进入 CLOSE_WAIT 状态，客户端收到后，进入 FIN_WAIT_2 状态。
- 服务端处理完未发送完的数据后，发送一个带 FIN 标志位的数据包，表示“我也没有数据要发了”。进入 LAST_ACK 状态。
- 客户端收到服务端的 FIN 后，发送 ACK 包，
    - 随后客户端进入 TIME_WAIT 状态，等待一段时间后，进入 CLOSED 状态。
    - 服务端收到 ACK 后立即关闭，进入 CLOSED 状态。



2. 数据分段和编号。

- 发送的数据被分成多个报文段，每个字节都有唯一的序列号（Sequence Number）。
- 这样接收方可以根据序列号正确排序数据，即使乱序到达也能还原原始顺序。

3. 确认应答机制。

- 每收到一段数据，接收方会发送确认应答（ACK），告知发送方“我收到了第X个字节”。
- 没有收到确认的报文段会被认为丢失，需要重发。

4. 超时重传机制。

- 发送方在发送数据后会启动定时器，如果在超时时间内没有收到 ACK，就会自动重传该数据段。
- 这样即使网络中有丢包，也能保证数据最终送达。

5. 数据校验和。

- TCP 报文有校验和字段，对头部和数据都进行校验，确保数据在传输过程中没有被篡改或损坏。
- 如果校验和出错，接收方会丢弃该数据段，发送方会重发。

6. 流量控制。

- 通过滑动窗口，接收方可以告诉发送方“我最多还能接收多少数据”，防止发送方发送过快导致接收方来不及处理。
- 保证双方的处理能力和网络状况匹配，避免丢包。

7. 拥塞控制

- 慢启动

TCP 连接建立后，发送方会设置一个很小的拥塞窗口（cwnd），比如 1 个 MSS（最大报文段。每收到一个 ACK，cwnd 就加倍（指数增长），即每轮发送的数据量翻倍。

- 拥塞避免

当 cwnd ≥ ssthresh 时，TCP 进入“拥塞避免”阶段。此时 cwnd 不再指数增长，而是线性增长，每收到一个 ACK，cwnd 增加 1/cwnd。

- 快重传

正常情况下，TCP 只有在超时后才重传丢失的数据，这样会浪费时间。发送方如果连续收到 3 个相同的 ACK（即 3 个重复 ACK），就会立即重传丢失的数据段，而不用等超时。

- 快恢复

当发生快重传时，ssthresh 设为当前 cwnd 的一半，cwnd 也降到一半（而不是降到 1）。进入快恢复阶段，cwnd 以线性方式增长，直到丢包问题解决。

8. 有序数据传输

即使数据包乱序到达，TCP 也会根据序列号重新排序，保证上层应用收到的数据是有序的


**举例说明**

假设你用 TCP 传输一段大文件，网络中间丢失了几个数据包：
1. 发送方把文件分成若干段，每段带有序列号，依次发送。
2. 接收方收到第 1、2、4 段，发现第 3 段没来，会等第 3 段。
3. 发送方因超时未收到第 3 段的 ACK，自动重发第 3 段。
4. 接收方收到第 3 段后，按序排列，确认无误后再交给上层应用。
5. 整个过程都在保证数据不丢失、不重复、不乱序。



### UDP 

#### 报文格式

<img src="net/http/resources/udp_1.png" style="width:30%">

- 源端口号（16位）：发送方端口
- 目标端口号（16位）：接收方端口
- 长度（16位）：整个UDP报文（头部+数据）的字节数
- 校验和（16位）：对UDP头部和数据的校验（可选，但在IPv6下必须填写）
- 数据：实际要传输的数据内容


## HTTP 0.9

<img src="net/http/resources/http_1.png" style="width:100%">

- 第一个是只有一个请求行，并没有HTTP 请求头和请求体，因为只需要一个请求行就可以完整表达客户端的需求了。
- 第二个是服务器也没有返回头信息，这是因为服务器端并不需要告诉客户端太多信息，只需要返回数据就可以了。
- 第三个是返回的文件内容是以 ASCII 字符流来传输的，因为都是 HTML 格式的文件，所以使用 ASCII 字节码来传输是最合适的。

## HTTP 1.0

后面，互联网页面的内容日益丰富。在浏览器中展示的不单是 HTML 文件了，还包括了 JavaScript、CSS、图片、音频、视频等不同类型的文件。因此支持多种类型的文件下载是 HTTP/1.0 的一个核心诉求，而且文件格式不仅仅局限于 ASCII 编码，还有很多其他类型编码的文件。

HTTP/1.0 引入了请求头和响应头,HTTP/1.0 的方案是通过请求头和响应头来进行协商，在发起请求时候会通过 HTTP 请求头告诉服务器它期待服务器返回什么类型的文件、采取什么形式的压缩、提供什么语言的文件以及文件的具体编码。

## HTTP 1.1

HTTP 1.0 不支持长连接，每一次获取数据都需要重新的建联，效率很低，而 1.1 版本就增加了持久连接的能力。一般而言，1.1 版本下，可以给一个域名同时维持最多6个长连接。

为了提升性能，HTTP/1.1 引入了管道化（Pipelining），允许在同一个连接上连续发送多个请求，但响应必须严格按照请求顺序返回。

同时为了确保安全，提供了 cookie 等一些安全机制。

## HTTP 2.0

HTTP1.1 版本还存在的问题：

- TCP 慢启动。
- 多个 TCP 连接竞争带宽。
- HTTP/1.1 管道化导致队头阻塞问题。就是前面的 HTTP 请求耗时过久会阻塞后续的请求。

针对这些问题，

- 为了避免慢启动以及多个TCP连接竞争的问题，对于一个域名，只使用一个 TCP 长连接。
- 为了避免队头阻塞问题，实现多路复用策略，即一个 HTTP 请求可以分成多个帧去发送。
- 增加优先级设置能力，服务段可以依据请求优先级，有限考虑返回更加关键的资源。


## HTTP 3.0

HTTP2.0 版本还存在的一个问题：
- TCP 队头阻塞：如果在数据传输的过程中，有一个数据因为网络故障或者其他原因而丢包了，那么整个 TCP 的连接就会处于暂停状态，需要等待丢失的数据包被重新传输过来。你可以把 TCP 连接看成是一个按照顺序传输数据的管道，管道中的任意一个数据丢失了，那之后的数据都需要等待该数据的重新传输。
- TCP 连接耗时过久。

基于上面的问题，HTTP3.0 版本决定抛弃 TCP 协议，基于 UDP 协议，并在上层封装传输可靠策略的 QUIC (Quick UDP Internet Connections) 协议。


## HTTPS

### 对称加密

<img src="net/http/resources/https_1.png" style="width:80%">

客户端和服务端明文传输自己的随机数，后续双端使用随机数生成密钥进行加密与解密。

通过将对称加密应用在安全层上，我们实现了第一个版本的 HTTPS，虽然这个版本能够很好地工作，但是其中传输 client-random 和 service-random 的过程却是明文的，这意味着黑客也可以拿到协商的加密套件和双方的随机数，由于利用随机数合成密钥的算法是公开的，所以黑客拿到随机数之后，也可以合成密钥，这样数据依然可以被破解，那么黑客也就可以使用密钥来伪造或篡改数据了。

### 非对称加密

<img src="net/http/resources/https_2.png" style="width:80%">

服务端会给客户端发送一个公钥，后续浏览器发送给服务端的数据使用公钥加密，服务端使用私钥解密。服务端发送给浏览器的使用私钥加密，浏览器使用公钥解密。

这样可以有效的保证服务端安全，因为我们不知道私钥，无法解析浏览器发送给服务端的数据。

但是没法保证浏览器安全，因为公钥我们可以捕获，并来解析服务端发送过来的数据。

### 非对称+对称

<img src="net/http/resources/https_3.png" style="width:80%">

1. 浏览器先使用非对称加密算法传一个随机数 pre-master，因为私钥在服务端，所以链路上没法解密。
2. 服务端拿到随机数 pre-master 后，使用非对称加密的私钥进行解密。
3. 服务端与浏览器随后包含着 pre-master 生成的秘钥进行对称加密传输。


### 数字证书

<img src="net/http/resources/https_4.png" style="width:80%">

上面非对称+对称加密的方式看起来已经很好的解决了数据破解的问题，但有的时候，别人会伪造站点，我们浏览器没法区分这个站点，为了避免伪造站点的问题，又提出了数字证书。

相较于第三版的 HTTPS 协议，这里主要有两点改变：
- 服务器没有直接返回公钥给浏览器，而是返回了数字证书，而公钥正是包含在数字证书中的；
- 在浏览器端多了一个证书验证的操作，验证了证书之后，才继续后续流程。



